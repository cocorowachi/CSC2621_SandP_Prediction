{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2093a0b-d537-459d-8e00-68e8dc301b41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1647c48b-0b12-422a-a457-45ef950b6dc7",
   "metadata": {},
   "source": [
    "# Deliverables\n",
    "1. Research Question\n",
    "    - Can we predict the S&P price over the next 10 days using financial indicators?\n",
    "3. Hypothesis\n",
    "    - Null: There are no correlations\n",
    "    - Alternative: There are correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff7311-b724-4989-9e88-093783e68e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_yield_df = pd.read_csv(\"Bond yield.csv\")\n",
    "cpi_df = pd.read_csv(\"Consumer price index.csv\")\n",
    "dj_df = pd.read_csv(\"Dow Jones.csv\")\n",
    "usd_eur_df = pd.read_csv(\"USD_EUR.csv\")\n",
    "usd_jpy_df = pd.read_csv(\"USD_JPY.csv\")\n",
    "gdp_df = pd.read_csv(\"GDP.csv\")\n",
    "national_hpi_df = pd.read_csv(\"National home price index.csv\")\n",
    "sp_df = pd.read_csv(\"S&P Price.csv\")\n",
    "\n",
    "dfs = [bond_yield_df, cpi_df, dj_df, usd_eur_df, usd_jpy_df, gdp_df, national_hpi_df, sp_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5350a3-0d07-4357-95b0-3200441918c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dfs)):\n",
    "    dfs[i].columns.values[0] = 'date'\n",
    "    dfs[i] = dfs[i].drop_duplicates(subset=\"date\", keep=\"first\") \n",
    "    \n",
    "    dfs[i].set_index('date', inplace=True)\n",
    "    dfs[i].index = pd.to_datetime(dfs[i].index, errors=\"coerce\").normalize()\n",
    "\n",
    "    dfs[i] = dfs[i][~dfs[i].index.duplicated(keep=\"first\")]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae4c03-fc23-480a-8a88-5494f476d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58aa459-f528-45bf-80bf-14b2dae7b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df[['Value', 'DJIA', 'GDP', 'DGS10', 'CSUSHPINSA', 'CPIAUCSL', 'EURO', 'JPY']]\n",
    "df.columns = ['SP_price','dow_jones','gdp','bond_yield','home_price_index','consumer_price_index','eur','jpy']\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "    # df[col] = pd.to_numeric(df[col])\n",
    "df.reset_index(inplace=True)\n",
    "full_date_range = pd.date_range(start=df['date'].min(), end=df['date'].max(), freq='D')\n",
    "df.set_index(\"date\", inplace=True) \n",
    "df = df.reindex(full_date_range)\n",
    "df.index.name = \"date\"\n",
    "\n",
    "df= df.ffill()\n",
    "\n",
    "df = df[df.index >= '1987-01-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e7d231-8a19-4400-8fb2-c749278bcc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_mirrored_rows(df, num_rows=30):\n",
    "    \"\"\"\n",
    "    Insert chronologically mirrored data point at head and tail of df\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    mirrored_rows_head = df.iloc[:num_rows].copy()\n",
    "    mirrored_rows_head = mirrored_rows_head.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "    mirrored_rows_tail = df.iloc[-num_rows:].copy()\n",
    "    mirrored_rows_tail = mirrored_rows_tail.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "    df_extended = pd.concat([mirrored_rows_head, df, mirrored_rows_tail], ignore_index=True)\n",
    "    \n",
    "    return df_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41243b6-d892-4773-8eab-d271c5fb034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SP_price_ln'] = np.log(df['SP_price'])\n",
    "df['dow_jones'] = pd.to_numeric(df['dow_jones'].str.replace(',', '', regex=True))\n",
    "\n",
    "extended_df = insert_mirrored_rows(df['SP_price'].copy(), 200)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b96f4db-23f0-46ec-8bbe-1f67585c051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma30_df = df.rolling(window=30).mean().reset_index().iloc[30:-30].reset_index(drop=True)\n",
    "ma100_df = df.rolling(window=100).mean().reset_index().iloc[100:-100].reset_index(drop=True)\n",
    "ma200_df = df.rolling(window=200).mean().reset_index().iloc[200:-200].reset_index(drop=True)\n",
    "df['SP_MA_30'] = df['SP_price'].rolling(window=30).mean()\n",
    "df['SP_MA_100'] = df['SP_price'].rolling(window=100).mean()\n",
    "df['SP_MA_200'] = df['SP_price'].rolling(window=200).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f2f4d-217d-46fd-8230-1539c27cc645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.reset_index(inplace=True)  # Move the index back to a column\n",
    "df.head(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20378c38-5822-44b6-917b-488724fec302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_of_month = df[df['date'].dt.day == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe60e6-1c4c-4d2b-a9b2-f6a10977294c",
   "metadata": {},
   "source": [
    "## Add timeseries features\n",
    "- For each daily feature, get the last 10 days for that feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0912782-d9aa-4548-b13f-0457cd4534ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dow_jones_ln'] = np.log(df['dow_jones'])\n",
    "df['gdp_ln'] = np.log(df['gdp'])\n",
    "df['home_price_index_ln'] = np.log(df['home_price_index'])\n",
    "df['bond_yield_ln'] = np.log(df['bond_yield'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66005152-7192-4cd6-8648-dd6a8044754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_features = [\"SP_price_ln\", \"dow_jones_ln\", \"gdp_ln\", \"eur\", \"jpy\", \"home_price_index_ln\", \"consumer_price_index\", \"bond_yield_ln\"]\n",
    "\n",
    "#################\n",
    "lookback = 20\n",
    "forecast = 5\n",
    "#################\n",
    "# Store all new columns in a dictionary first\n",
    "new_cols = {}\n",
    "\n",
    "# Forecast columns (shift forward)\n",
    "for f in daily_features:\n",
    "    new_cols[f + f\"+{forecast}\"] = df[f].shift(-forecast)\n",
    "\n",
    "# Lookback columns (shift backward)\n",
    "for f in daily_features:\n",
    "    for i in range(1, lookback + 1):\n",
    "        new_cols[f + f\"-{i}\"] = df[f].shift(i)\n",
    "\n",
    "# Combine all at once using pd.concat\n",
    "df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "\n",
    "# df.iloc[35177:35187]\n",
    "df_with_wknd = df.copy()\n",
    "df = df[df['date'].dt.weekday < 5].reset_index(drop=True)\n",
    "i = 1\n",
    "for col in df.columns:\n",
    "    print(i, col)\n",
    "    i+=1\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efd91c-8769-4ffa-a00b-3fc9a2e800ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df['date'].dt.year >= 1980) & (df['date'].dt.year <= 2020)]\n",
    "col =  df.iloc[:, 26:].columns\n",
    "df_filtered = df_filtered.dropna(subset=col)\n",
    "\n",
    "X = df_filtered[col]\n",
    "y = df_filtered[f'SP_price_ln+{forecast}']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "\n",
    "# Predict on new data\n",
    "predictions = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab9223-7b36-46d1-a75f-8d16f1daf52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 5))\n",
    "plt.plot(df_filtered['date'], df_filtered['SP_price'], linestyle='-', color='b', linewidth=1, label=\"data\")\n",
    "plt.plot(df_filtered['date'], math.e**predictions, linestyle='-', color='g', linewidth=1, label=\"data\")\n",
    "plt.show()\n",
    "r, p_value = pearsonr(df_filtered['SP_price'], math.e**predictions)\n",
    "mse = mean_squared_error(df_filtered['SP_price'], math.e**predictions)\n",
    "print(r)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7f5fb-e336-451c-9371-f8b924ca04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = df[df['date'] == '2020-12-31'][col]\n",
    "\n",
    "# Make the prediction\n",
    "predicted_ln = model.predict(X_new)\n",
    "\n",
    "# Convert the log prediction back to the actual price\n",
    "predicted_price = np.exp(predicted_ln)\n",
    "\n",
    "# Print the predicted price\n",
    "print(f\"Predicted S&P price for 2021-01-10: {predicted_price[0]:.2f}\")\n",
    "\n",
    "value = df[df['date'] == '2020-12-31']['SP_price'].values[0]\n",
    "print(f\"Actual S&P price for 2021-01-10: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4082c78-3962-41c8-b080-4575aa1d5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined = []\n",
    "for i in range(len(col)):\n",
    "    if abs(model.coef_[i]) > 0.075:\n",
    "        refined.append(col[i])\n",
    "        print(col[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde4628-256e-4f5f-b024-118901786991",
   "metadata": {},
   "outputs": [],
   "source": [
    "col =  refined\n",
    "X = df_filtered[col]\n",
    "y = df_filtered[f'SP_price_ln+{forecast}']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "\n",
    "# Predict on new data\n",
    "predictions2 = model.predict(X)\n",
    "\n",
    "plt.figure(figsize=(200, 5))\n",
    "plt.plot(df_filtered['date'], df_filtered['SP_price'], linestyle='-', color='b', markersize=6, label=\"data\")\n",
    "plt.plot(df_filtered['date'], math.e**predictions2, linestyle='-', color='g', markersize=6, label=\"data\")\n",
    "plt.show()\n",
    "r, p_value = pearsonr(df_filtered['SP_price'], math.e**predictions2)\n",
    "mse = mean_squared_error(df_filtered['SP_price'], math.e**predictions2)\n",
    "print(r)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629c476-45aa-4645-8f33-36d0833e2f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model3 = df[(df['date'].dt.year >= 1980) & (df['date'].dt.year <= 2020)]\n",
    "normalized = df_model3.copy()\n",
    "scaler = StandardScaler()\n",
    "y_col = \"SP_price_ln\"\n",
    "features = normalized.drop(columns=[\"date\",y_col,\"SP_price\"] + list(filter(lambda x: '+' in x, normalized.columns)))\n",
    "y=df_model3[y_col]\n",
    "scaled_array = scaler.fit_transform(features)\n",
    "normalized = pd.DataFrame(scaled_array, index=features.index, columns=features.columns)\n",
    "normalized[y_col] = y\n",
    "\n",
    "n = len(normalized)\n",
    "def adj_r2(R2, p):\n",
    "    \"\"\"Adjusted r^2 score from R^2, and number of features\"\"\"\n",
    "    return 1-(1-R2)*(n-1)/(n-p-1)\n",
    "\n",
    "# Model 3 (using greedy algorithm)\n",
    "mod_3_scores = []\n",
    "for c in normalized.columns:\n",
    "    if c == y_col: continue\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    \n",
    "    working_df = normalized.dropna(subset=[y_col,c])\n",
    "    col = working_df[c].to_numpy().reshape(-1,1)\n",
    "    model.fit(col,working_df[y_col])\n",
    "    score = adj_r2(model.score(col,working_df[y_col]),1)\n",
    "    mod_3_scores.append((c,score))\n",
    "\n",
    "mod_3_scores = sorted(mod_3_scores, key=lambda x: x[1],reverse=True)\n",
    "# print(\"Sorted scores for individual linear regressions:\")\n",
    "# print(mod_3_scores)\n",
    "\n",
    "mod_3_score = 0\n",
    "mod_3_cols = []\n",
    "reg3 = LinearRegression(fit_intercept=True)\n",
    "for c,_ in mod_3_scores:\n",
    "    working_df = normalized.dropna(subset=mod_3_cols+[c,y_col])\n",
    "    X = working_df[mod_3_cols + [c]]\n",
    "    reg3.fit(X,working_df[y_col])\n",
    "    score = adj_r2(reg3.score(X,working_df[y_col]),len(mod_3_cols) + 1)\n",
    "    if score > mod_3_score:\n",
    "        mod_3_score = score\n",
    "        mod_3_cols += [c]\n",
    "\n",
    "final_scaler = StandardScaler()\n",
    "\n",
    "working_df = df_model3.dropna(subset=mod_3_cols + [y_col])\n",
    "X3_raw = working_df[mod_3_cols]\n",
    "X3_scaled = pd.DataFrame(final_scaler.fit_transform(X3_raw), columns=mod_3_cols)\n",
    "\n",
    "reg3.fit(X3_scaled, working_df[y_col])\n",
    "trained_features = mod_3_cols.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d828a-6396-4e17-a3e1-4c1c54695d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = df[df['date'] == '2020-12-31']\n",
    "X_new_raw = X_filtered[trained_features].copy()\n",
    "\n",
    "# Fill missing columns if needed\n",
    "for col in trained_features:\n",
    "    if col not in X_new_raw.columns:\n",
    "        X_new_raw[col] = np.nan \n",
    "\n",
    "X_new_scaled = pd.DataFrame(final_scaler.transform(X_new_raw), columns=trained_features)\n",
    "\n",
    "predicted_ln = reg3.predict(X_new_scaled)\n",
    "predicted_price = np.exp(predicted_ln)\n",
    "\n",
    "print(f\"Predicted S&P price for 2021-01-10: {predicted_price[0]:.2f}\")\n",
    "\n",
    "value = df[df['date'] == '2020-12-31']['SP_price'].values[0]\n",
    "print(f\"Actual S&P price for 2021-01-10: {value}\")\n",
    "\n",
    "# print(\"Coefficients:\", reg3.coef_)\n",
    "# print(\"Intercept:\", reg3.intercept_)\n",
    "# print(\"Input features:\", X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5060874e-ed9a-49fe-8960-600b3cc0abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "lookback = lookback\n",
    "forecast_horizon = forecast\n",
    "##############\n",
    "\n",
    "feature_cols = df.iloc[:, 26:].columns\n",
    "\n",
    "df_model = df.iloc[lookback:12054, 26:].copy()\n",
    "df_model['date'] = df.iloc[lookback:12054, 0].values\n",
    "\n",
    "target_cols = []\n",
    "for step in range(1, forecast_horizon + 1):\n",
    "    col_name = f'target_day_{step}'\n",
    "    df_model[col_name] = df['SP_price_ln'].shift(-step + 1)\n",
    "    target_cols.append(col_name)\n",
    "\n",
    "df_model = df_model.dropna(subset=target_cols)\n",
    "\n",
    "X = df_model[feature_cols].values\n",
    "Y = df_model[target_cols].values  # shape: (n_samples, 5)\n",
    "\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "Y_train, Y_test = Y[:split_idx], Y[split_idx:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression().fit(X_train_scaled, Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e329313c-da28-4ed6-8876-61f2f36ff014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictions_leading_up(selected_date, forecast_=5, window=30):\n",
    "    selected_date = pd.to_datetime(selected_date)\n",
    "    \n",
    "    selected_idx = df[df['date'] == selected_date].index[0]\n",
    "    \n",
    "    feature_values = df.iloc[selected_idx, 26:].values.reshape(1, -1)\n",
    "    feature_scaled = scaler.transform(feature_values)\n",
    "    \n",
    "    predicted_values = model.predict(feature_scaled)[0]\n",
    "    \n",
    "    prediction_date_indices = [selected_idx + i for i in range(1, forecast_ + 1)]\n",
    "    valid_indices = [idx for idx in prediction_date_indices if idx < len(df)]\n",
    "    predicted_prices = np.exp(predicted_values[:len(valid_indices)])\n",
    "    \n",
    "    plot_start = max(0, selected_idx - window)\n",
    "    plot_end = min(len(df), selected_idx + forecast_ + window)\n",
    "    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    plt.plot(df.index[plot_start:plot_end], df['SP_price'].iloc[plot_start:plot_end], label='Actual S&P 500', color='blue')\n",
    "    \n",
    "    plt.plot(valid_indices, predicted_prices, 'ro--', label=f'Predicted price (next {forecast_} days)')\n",
    "    \n",
    "    plt.axvline(x=selected_idx, color='green', linestyle=':', label=f'Selected Date: {selected_date.date()}')\n",
    "    \n",
    "    xticks = df.index[plot_start:plot_end:5]\n",
    "    xlabels = df['date'].iloc[plot_start:plot_end:5].dt.strftime('%Y-%m-%d')\n",
    "    plt.xticks(ticks=xticks, labels=xlabels, rotation=45)\n",
    "    \n",
    "    plt.title(f\"Past {window} days + {forecast_} days forecast from {selected_date.date()}\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('S&P 500 Price')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94806d3b-3703-4489-8eab-56368dd41289",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_leading_up('2020-8-17', forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac9ef0-20bf-4177-98a6-f55ab54f822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dfff.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416bab64-fe44-4fb5-b806-014b7226471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model3 = df[(df['date'].dt.year >= 1980) & (df['date'].dt.year <= 2020)]\n",
    "normalized = df_model3.copy()\n",
    "scaler = StandardScaler()\n",
    "y_col = \"SP_price_ln\"\n",
    "\n",
    "features = df.iloc[:, 26:]\n",
    "print(features)\n",
    "y = df_model3[y_col]\n",
    "\n",
    "scaled_array = scaler.fit_transform(features)\n",
    "normalized = pd.DataFrame(scaled_array, index=features.index, columns=features.columns)\n",
    "normalized[y_col] = y\n",
    "\n",
    "n = len(normalized)\n",
    "def adj_r2(R2, p):\n",
    "    return 1 - (1-R2) * (n-1) / (n-p-1)\n",
    "\n",
    "mod_3_scores = []\n",
    "for c in normalized.columns:\n",
    "    if c == y_col: continue\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    working_df = normalized.dropna(subset=[y_col, c])\n",
    "    col = working_df[c].to_numpy().reshape(-1, 1)\n",
    "    model.fit(col, working_df[y_col])\n",
    "    score = adj_r2(model.score(col, working_df[y_col]), 1)\n",
    "    mod_3_scores.append((c, score))\n",
    "\n",
    "mod_3_scores = sorted(mod_3_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "mod_3_score = 0\n",
    "mod_3_cols = []\n",
    "reg3 = LinearRegression(fit_intercept=True)\n",
    "for c, _ in mod_3_scores:\n",
    "    working_df = normalized.dropna(subset=mod_3_cols + [c, y_col])\n",
    "    X = working_df[mod_3_cols + [c]]\n",
    "    reg3.fit(X, working_df[y_col])\n",
    "    score = adj_r2(reg3.score(X, working_df[y_col]), len(mod_3_cols) + 1)\n",
    "    if score > mod_3_score:\n",
    "        mod_3_score = score\n",
    "        mod_3_cols += [c]\n",
    "\n",
    "# Train final model\n",
    "final_scaler = StandardScaler()\n",
    "working_df = df_model3.dropna(subset=mod_3_cols + [y_col])\n",
    "X3_raw = working_df[mod_3_cols]\n",
    "X3_scaled = pd.DataFrame(final_scaler.fit_transform(X3_raw), columns=mod_3_cols)\n",
    "reg3.fit(X3_scaled, working_df[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9104c9-f4fe-4008-a9e5-9d3f09420fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_fast(selected_date, forecast_horizon=5, window=30):\n",
    "    selected_date = pd.to_datetime(selected_date)\n",
    "    \n",
    "    selected_idx = df[df['date'] == selected_date].index[0]\n",
    "    \n",
    "    predicted_prices = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for offset in range(forecast_horizon):\n",
    "        idx = selected_idx + offset\n",
    "        X_row = df.iloc[idx]\n",
    "        X_features = X_row[mod_3_cols].to_frame().T\n",
    "        X_scaled = pd.DataFrame(final_scaler.transform(X_features), columns=mod_3_cols)\n",
    "        pred_ln = reg3.predict(X_scaled)[0]\n",
    "        pred_price = np.exp(pred_ln)\n",
    "        \n",
    "        predicted_prices.append(pred_price)\n",
    "        valid_indices.append(idx)\n",
    "    \n",
    "    plot_start = selected_idx - window\n",
    "    plot_end = selected_idx + forecast_horizon + window\n",
    "    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    plt.plot(df.index[plot_start:plot_end], df['SP_price'].iloc[plot_start:plot_end], label='Actual S&P 500', color='blue')\n",
    "    plt.plot(valid_indices, predicted_prices, 'ro--', label=f'Predicted price (next {forecast_horizon} days)')\n",
    "    \n",
    "    plt.axvline(x=selected_idx, color='green', linestyle=':', label=f'Selected Date: {selected_date.date()}')\n",
    "    \n",
    "    # Custom x-axis ticks/labels\n",
    "    xticks = df.index[plot_start:plot_end:5]\n",
    "    xlabels = df['date'].iloc[plot_start:plot_end:5].dt.strftime('%Y-%m-%d')\n",
    "    plt.xticks(ticks=xticks, labels=xlabels, rotation=45)\n",
    "    \n",
    "    plt.title(f\"Past {window} days + {forecast_horizon} days forecast from {selected_date.date()}\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('S&P 500 Price')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555773e-76ad-49aa-8f13-6d35977472bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_fast('2023-1-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7a7c6-a970-4d64-b402-0d213f56ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_fast('2023-12-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa9db4a-0384-49e8-8362-1be5312ae342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
